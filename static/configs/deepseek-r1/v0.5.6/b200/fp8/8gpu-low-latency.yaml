# DeepSeek-R1 FP8 on B200 (8 GPU) - Low Latency Configuration
# Optimized for: Minimum TTFT, real-time chat, streaming responses
# Hardware: 8x NVIDIA B200
# Source: SGLang Cookbook v0.5.6

model_path: deepseek-ai/DeepSeek-R1-0528
tensor_parallel_size: 8
data_parallel_size: 1
cuda_graph_max_bs: 128
max_running_requests: 128
mem_fraction_static: 0.82
kv_cache_dtype: fp8_e4m3
chunked_prefill_size: 32768
max_prefill_tokens: 32768
enable_flashinfer_allreduce_fusion: true
scheduler_recv_interval: 10
disable_radix_cache: true
attention_backend: trtllm_mla
stream_interval: 30
ep_size: 1
moe_runner_backend: flashinfer_trtllm
quantization: fp8
