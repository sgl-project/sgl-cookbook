# Mistral AI Model Configurations
# This file is compiled to data/models/generated/mistral.yaml

vendor: mistralai

defaults:
  hardware:
    H100: { tp: 1 }
    H200: { tp: 1 }
    A100: { tp: 1 }
  configurations:
    - name: default
      nodes: single
      optimization: balanced
      extra_args:
        - --trust-remote-code

families:
  - name: Mistral-Small-3
    description: Mistral Small 3 (24B) Instruct Model
    llm:
      thinking_capability: non_thinking
    models:
      - name: Mistral-Small-24B-Instruct-2501
        model_path: mistralai/Mistral-Small-24B-Instruct-2501
        quantization: bf16
        hardware:
          A100: { tp: 2 } # 24B * 2 = 48GB > 40GB

  - name: Mistral-Large-2
    description: Mistral Large 2 (123B) Instruct Model
    llm:
      thinking_capability: non_thinking
    models:
      - name: Mistral-Large-Instruct-2407
        model_path: mistralai/Mistral-Large-Instruct-2407
        quantization: bf16
        hardware:
          H100: { tp: 4 }
          H200: { tp: 4 }
          A100: { tp: 8 }

  - name: Mistral-Nemo
    description: Mistral Nemo (12B) Instruct Model (Often used as "Medium" class)
    llm:
      thinking_capability: non_thinking
    models:
      - name: Mistral-Nemo-12B-Instruct-v1
        model_path: mistralai/Mistral-Nemo-12B-Instruct-v1
        quantization: bf16
