# DeepSeek-R1 Model Configurations (Simplified Format)
# This file is compiled to data/models/generated/deepseek-r1.yaml
#
# Note: B200 hardware includes --kv-cache-dtype fp8_e4m3 for improved performance
# with fp8 attention kernels. H100/H200 use default kv-cache dtype.

vendor: deepseek-ai

defaults:
  hardware:
    H100: { tp: 8 }
    H200: { tp: 8 }
    B200: { tp: 8, extra_args: ["--kv-cache-dtype", "fp8_e4m3"] }
  configurations:
    - name: default
      nodes: single
      optimization: balanced
      extra_args:
        - --enable-symm-mem
    - name: high-throughput-dp
      nodes: single
      optimization: high-throughput
      dp: 8
      enable_dp_attention: true
      extra_args:
        - --enable-symm-mem
    - name: high-throughput-ep
      nodes: single
      optimization: high-throughput
      ep: 8
      extra_args:
        - --enable-symm-mem
    - name: speculative-mtp
      nodes: single
      optimization: low-latency
      env_vars:
        SGLANG_ENABLE_SPEC_V2: "1"
      extra_args:
        - --enable-symm-mem
        - --speculative-algorithm
        - EAGLE
        - --speculative-num-steps
        - "3"
        - --speculative-eagle-topk
        - "1"
        - --speculative-num-draft-tokens
        - "4"

families:
  - name: DeepSeek-R1
    description: DeepSeek R1 reasoning model with extended thinking capabilities
    llm:
      thinking_capability: thinking
      tool_parser: deepseekv3
      reasoning_parser: deepseek-r1
      chat_template: examples/chat_template/tool_chat_template_deepseekr1.jinja

    models:
      # DeepSeek-R1-0528 FP8 - all hardware
      - name: DeepSeek-R1-0528
        model_path: deepseek-ai/DeepSeek-R1-0528
        quantization: fp8

      # DeepSeek-R1-0528 FP4 - only H200/B200 supported
      - name: DeepSeek-R1-0528-FP4
        model_path: nvidia/DeepSeek-R1-0528-FP4-v2
        quantization: fp4
        hardware:
          H200: { tp: 8 }
          B200: { tp: 8 }
