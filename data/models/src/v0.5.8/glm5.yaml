# GLM-5 Model Configurations (Simplified Format)
# This file is compiled to data/models/generated/glm5.yaml
#
# GPU requirements (BF16 needs 2x GPUs compared to FP8):
#   H100: FP8 tp=16, BF16 tp=32
#   H200: FP8 tp=8, BF16 tp=16
#   B200: FP8 tp=8, BF16 tp=16

vendor: zai-org

defaults:
  hardware:
    H100: { tp: 16 }
    H200: { tp: 8 }
    B200: { tp: 8 }
  configurations:
    - name: default
      nodes: single
      optimization: balanced
    - name: high-throughput-dp
      nodes: single
      optimization: high-throughput
      dp: 8
      enable_dp_attention: true
    - name: speculative-mtp
      nodes: single
      optimization: low-latency
      extra_args:
        - --speculative-algorithm
        - EAGLE
        - --speculative-num-steps
        - "3"
        - --speculative-eagle-topk
        - "1"
        - --speculative-num-draft-tokens
        - "4"

families:
  - name: GLM-5
    description: GLM-5 744B (40B active) MoE model with reasoning, coding, and agentic capabilities
    llm:
      thinking_capability: hybrid
      tool_parser: glm47
      reasoning_parser: glm45

    models:
      # GLM-5 BF16 - needs 2x GPUs compared to FP8
      - name: GLM-5
        quantization: bf16
        hardware:
          H100: { tp: 32 }
          H200: { tp: 16 }
          B200: { tp: 16 }

      # GLM-5 FP8
      - name: GLM-5-FP8
        quantization: fp8
