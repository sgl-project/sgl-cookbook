vendor: nvidia
families:
- name: Nemotron-Nano-3
  description: NVIDIA Nemotron-3-Nano-30B-A3B model
  models:
  - name: NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
    model_path: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
    attributes:
      llm:
        thinking_capability: hybrid
        tool_parser: qwen3_coder
        reasoning_parser: nano_v3
        chat_template: null
    hardware:
      H200:
        configurations:
        - name: default
          attributes:
            nodes: single
            optimization: balanced
            quantization: bf16
          quantized_model_path: null
          engine:
            env_vars: {}
            tp: 1
            dp: null
            ep: null
            enable_dp_attention: null
            extra_args: []
          prefill: null
          decode: null
      B200:
        configurations:
        - name: default
          attributes:
            nodes: single
            optimization: balanced
            quantization: bf16
          quantized_model_path: null
          engine:
            env_vars: {}
            tp: 1
            dp: null
            ep: null
            enable_dp_attention: null
            extra_args: []
          prefill: null
          decode: null
  - name: NVIDIA-Nemotron-3-Nano-30B-A3B-FP8
    model_path: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8
    attributes:
      llm:
        thinking_capability: hybrid
        tool_parser: qwen3_coder
        reasoning_parser: nano_v3
        chat_template: null
    hardware:
      H200:
        configurations:
        - name: default
          attributes:
            nodes: single
            optimization: balanced
            quantization: fp8
          quantized_model_path: null
          engine:
            env_vars: {}
            tp: 1
            dp: null
            ep: null
            enable_dp_attention: null
            extra_args: []
          prefill: null
          decode: null
      B200:
        configurations:
        - name: default
          attributes:
            nodes: single
            optimization: balanced
            quantization: fp8
          quantized_model_path: null
          engine:
            env_vars: {}
            tp: 1
            dp: null
            ep: null
            enable_dp_attention: null
            extra_args: []
          prefill: null
          decode: null
